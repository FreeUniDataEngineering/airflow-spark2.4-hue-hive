version: '2'
services:
  postgres:
    image: postgres:9.6
    volumes:
      - /d/BigDataPlayground/local/arf_pg_data:/var/lib/postgresql/data
    ports:
      - "5433"
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
      PGPORT: 5433
    restart: always
  airflow_with_spark:
    image: docker.io/anajaparidze/airflow_spark:airflow_2.1.4-spark_2.4.7
    ports:
      - "5433"
      - 8080:8080
    environment:
      AIRFLOW__CORE__FERNET_KEY: 8NE6O6RcTJpxcCkuKxOHOExzIJkXkeJKbRie03a69dI=
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql://airflow:airflow@postgres:5433/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor      
    restart: always
    command: ["bash", "-c", "echo '### Testing connection... '
                            && python test_db_conn.py 
                            && echo '### Running DB Init... '
                            && airflow db init 
                            && echo '### Starting scheduler... '
                            && airflow scheduler -D
                            && echo '### Sleeping 10 seconds... '                            
                            && sleep 10
                            && echo '### Starting webserver... '                            
                            && airflow webserver"]
    volumes:
      - /d/BigDataPlayground/local/dags:/airflow/dags
      - /d/BigDataPlayground/local/jobs:/airflow/jobs
      - /d/BigDataPlayground/local/data:/airflow/data    
      - airflow_logs:/airflow/logs/  

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    volumes:
      - //d/BigDataPlayground/local/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop-hive.env
    ports:
      - "50070:50070"
    
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - //d/BigDataPlayground/local/datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    ports:
      - "50075:50075"

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop2.7.4-java8
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075"
    env_file:
      - ./hadoop-hive.env

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432 resourcemanager:8088"
    ports:
      - "9083:9083"

  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    ports:
      - "5432"

  huedb:
    image: postgres:12.1-alpine
    volumes:
      - //d/BigDataPlayground/local/hive_pg_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    env_file:
      - ./hadoop-hive.env
    environment:
        SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432 resourcemanager:8088 hive-metastore:9083"
  
  hue:
    image: gethue/hue:4.6.0
    environment:
        SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432 resourcemanager:8088 hive-metastore:9083 huedb:5000"
    ports:
      - "8888:8888"
    volumes:
      - ./hue-overrides.ini:/usr/share/hue/desktop/conf/hue-overrides.ini
    links:
      - huedb

  pyspark-notebook:
      image: kublr/pyspark-notebook:spark-2.4.0-hadoop-2.6
      volumes:
        - //d/BigDataPlayground/local/notebooks:/jupyter
      user: root
      container_name: pyspark-notebook
      hostname: pyspark-notebook
      ports:
        - 8282:8888             
        - 4040:4040
        - 4041:4041
        - 4042:4042
        - 4043:4043        
        - 4044:4044
        - 4045:4045
      environment:
        JUPYTER_TOKEN: token
volumes:
  # pg_data: 
  #   driver: local
  #   driver_opts:
  #     type: none
  #     o: bind
  #     device: //d/BigDataPlayground/local/hive_pg_data
  airflow_logs: {}
